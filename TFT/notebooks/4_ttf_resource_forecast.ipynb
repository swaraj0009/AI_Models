{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: write code for google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9imFCsDrwtVO",
        "outputId": "02607137-2b90-4d1c-8ddb-65e7c9cc07da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install Required Packages\n",
        "# !pip install torch pytorch-forecasting pytorch-lightning rich colorama matplotlib seaborn pandas numpy tensorboard lightning[extra] pyarrow fastparquet"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C9TAeg3MxRMV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zMD5usllwmtY"
      },
      "outputs": [],
      "source": [
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "from pytorch_lightning import Trainer\n",
        "import torch\n",
        "import dask.dataframe as dd\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import glob\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V6OloX8FwmtZ"
      },
      "outputs": [],
      "source": [
        "df3 = dd.read_parquet(\"/content/drive/MyDrive/datasets/processed/FeatureEngcolab.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df3.columns.tolist())"
      ],
      "metadata": {
        "id": "TFFclZtb1XaB",
        "outputId": "73b8edfe-ee46-4765-86f4-fbf380c7230e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Timestamp [s]', 'CPU cores', 'CPU capacity provisioned [MHZ]', 'CPU usage [MHZ]', 'CPU usage [%]', 'Memory capacity provisioned [KB]', 'Memory usage [KB]', 'Disk read throughput [KB/s]', 'Disk write throughput [KB/s]', 'Network received throughput [KB/s]', 'Network transmitted throughput [KB/s]', 'VM', 'Timestamp', 'time_idx', 'time_diff', 'hour', 'dayofweek', 'is_weekend', 'month', 'day', 'hour_sin', 'hour_cos', 'dayofweek_sin', 'dayofweek_cos', 'month_sin', 'month_cos', 'cpu_utilization_ratio', 'memory_utilization_ratio', 'cpu_util_percent', 'memory_util_percent', 'cpu_util_prev', 'cpu_util_diff', 'memory_util_prev', 'memory_util_diff', 'disk_total_throughput', 'disk_rolling_mean', 'disk_rolling_std', 'network_total_throughput', 'network_rolling_mean', 'network_rolling_std', 'disk_read_prev', 'disk_read_diff', 'disk_write_prev', 'disk_write_diff', 'network_received_prev', 'network_received_diff', 'network_transmitted_prev', 'network_transmitted_diff', 'network_total_prev', 'network_total_diff']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df3.rename(columns={'VM': 'vm_id'})"
      ],
      "metadata": {
        "id": "qBhWeCT44vGY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9c6nIiic4xBB",
        "outputId": "90320aae-6292-4d72-957b-e8fe32f95b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dask DataFrame Structure:\n",
              "              Timestamp [s] CPU cores CPU capacity provisioned [MHZ] CPU usage [MHZ] CPU usage [%] Memory capacity provisioned [KB] Memory usage [KB] Disk read throughput [KB/s] Disk write throughput [KB/s] Network received throughput [KB/s] Network transmitted throughput [KB/s]   vm_id       Timestamp time_idx        time_diff   hour dayofweek is_weekend  month    day hour_sin hour_cos dayofweek_sin dayofweek_cos month_sin month_cos cpu_utilization_ratio memory_utilization_ratio cpu_util_percent memory_util_percent cpu_util_prev cpu_util_diff memory_util_prev memory_util_diff disk_total_throughput disk_rolling_mean disk_rolling_std network_total_throughput network_rolling_mean network_rolling_std disk_read_prev disk_read_diff disk_write_prev disk_write_diff network_received_prev network_received_diff network_transmitted_prev network_transmitted_diff network_total_prev network_total_diff\n",
              "npartitions=3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "                      int64     int64                        float64         float64       float64                          float64           float64                     float64                      float64                            float64                               float64  string  datetime64[ns]    int64  timedelta64[ns]  int32     int32       bool  int32  int32  float64  float64       float64       float64   float64   float64               float64                  float64          float64             float64       float64       float64          float64          float64               float64           float64          float64                  float64              float64             float64        float64        float64         float64         float64               float64               float64                  float64                  float64            float64            float64\n",
              "                        ...       ...                            ...             ...           ...                              ...               ...                         ...                          ...                                ...                                   ...     ...             ...      ...              ...    ...       ...        ...    ...    ...      ...      ...           ...           ...       ...       ...                   ...                      ...              ...                 ...           ...           ...              ...              ...                   ...               ...              ...                      ...                  ...                 ...            ...            ...             ...             ...                   ...                   ...                      ...                      ...                ...                ...\n",
              "                        ...       ...                            ...             ...           ...                              ...               ...                         ...                          ...                                ...                                   ...     ...             ...      ...              ...    ...       ...        ...    ...    ...      ...      ...           ...           ...       ...       ...                   ...                      ...              ...                 ...           ...           ...              ...              ...                   ...               ...              ...                      ...                  ...                 ...            ...            ...             ...             ...                   ...                   ...                      ...                      ...                ...                ...\n",
              "                        ...       ...                            ...             ...           ...                              ...               ...                         ...                          ...                                ...                                   ...     ...             ...      ...              ...    ...       ...        ...    ...    ...      ...      ...           ...           ...       ...       ...                   ...                      ...              ...                 ...           ...           ...              ...              ...                   ...               ...              ...                      ...                  ...                 ...            ...            ...             ...             ...                   ...                   ...                      ...                      ...                ...                ...\n",
              "Dask Name: operation, 2 expressions\n",
              "Expr=RenameFrame(frame=ReadParquetFSSpec(ac8f565), columns={'VM': 'vm_id'})"
            ],
            "text/html": [
              "<div><strong>Dask DataFrame Structure:</strong></div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp [s]</th>\n",
              "      <th>CPU cores</th>\n",
              "      <th>CPU capacity provisioned [MHZ]</th>\n",
              "      <th>CPU usage [MHZ]</th>\n",
              "      <th>CPU usage [%]</th>\n",
              "      <th>Memory capacity provisioned [KB]</th>\n",
              "      <th>Memory usage [KB]</th>\n",
              "      <th>Disk read throughput [KB/s]</th>\n",
              "      <th>Disk write throughput [KB/s]</th>\n",
              "      <th>Network received throughput [KB/s]</th>\n",
              "      <th>Network transmitted throughput [KB/s]</th>\n",
              "      <th>vm_id</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>time_idx</th>\n",
              "      <th>time_diff</th>\n",
              "      <th>hour</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>dayofweek_sin</th>\n",
              "      <th>dayofweek_cos</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "      <th>cpu_utilization_ratio</th>\n",
              "      <th>memory_utilization_ratio</th>\n",
              "      <th>cpu_util_percent</th>\n",
              "      <th>memory_util_percent</th>\n",
              "      <th>cpu_util_prev</th>\n",
              "      <th>cpu_util_diff</th>\n",
              "      <th>memory_util_prev</th>\n",
              "      <th>memory_util_diff</th>\n",
              "      <th>disk_total_throughput</th>\n",
              "      <th>disk_rolling_mean</th>\n",
              "      <th>disk_rolling_std</th>\n",
              "      <th>network_total_throughput</th>\n",
              "      <th>network_rolling_mean</th>\n",
              "      <th>network_rolling_std</th>\n",
              "      <th>disk_read_prev</th>\n",
              "      <th>disk_read_diff</th>\n",
              "      <th>disk_write_prev</th>\n",
              "      <th>disk_write_diff</th>\n",
              "      <th>network_received_prev</th>\n",
              "      <th>network_received_diff</th>\n",
              "      <th>network_transmitted_prev</th>\n",
              "      <th>network_transmitted_diff</th>\n",
              "      <th>network_total_prev</th>\n",
              "      <th>network_total_diff</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>npartitions=3</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>int64</td>\n",
              "      <td>int64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>string</td>\n",
              "      <td>datetime64[ns]</td>\n",
              "      <td>int64</td>\n",
              "      <td>timedelta64[ns]</td>\n",
              "      <td>int32</td>\n",
              "      <td>int32</td>\n",
              "      <td>bool</td>\n",
              "      <td>int32</td>\n",
              "      <td>int32</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<div>Dask Name: operation, 2 expressions</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JpDH8N3TwmtZ"
      },
      "outputs": [],
      "source": [
        "tft_df = df3.dropna(subset=[\n",
        "    'cpu_utilization_ratio',\n",
        "    'memory_utilization_ratio',\n",
        "    'disk_total_throughput',\n",
        "    'network_total_throughput'\n",
        "]).compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cy8HwIjFwmtZ"
      },
      "outputs": [],
      "source": [
        "# Define target variables\n",
        "# targets = ['cpu_utilization_ratio', 'memory_utilization_ratio', 'disk_total_throughput', 'network_total_throughput']\n",
        "\n",
        "targets = ['cpu_utilization_ratio']\n",
        "time_varying_known_reals = [\n",
        "    'time_idx',\n",
        "    'hour_sin', 'hour_cos',\n",
        "    'dayofweek_sin', 'dayofweek_cos',\n",
        "    'month_sin', 'month_cos'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHJkE0vkwmtZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import shutil\n",
        "\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "\n",
        "# 🔧 Unified config: change here only\n",
        "train_config = {\n",
        "    \"targets\": ['cpu_utilization_ratio'],  # change to full list if needed\n",
        "    \"time_varying_known_reals\": ['time_idx', 'hour_sin', 'hour_cos', 'dayofweek_sin', 'dayofweek_cos', 'month_sin', 'month_cos'],\n",
        "    \"group_ids\": ['vm_id'],\n",
        "    \"max_encoder_length\": 8,\n",
        "    \"max_prediction_length\": 2,\n",
        "    \"hidden_size\": 4,\n",
        "    \"dropout\": 0.1,\n",
        "    \"learning_rate\": 0.03,\n",
        "    \"batch_size\": 4,\n",
        "    \"epochs\": 1,\n",
        "    \"loss_fn\": RMSE(),\n",
        "    \"output_base_dir\": \"/home/output\",\n",
        "    \"log_dir\": \"/home/output/logs\",\n",
        "    \"accelerator_opt\": \"cpu\",\n",
        "}\n",
        "\n",
        "# 🚀 Run for each target\n",
        "for target in train_config[\"targets\"]:\n",
        "    print(f\"\\n🔁 Training for target: {target}\")\n",
        "\n",
        "    print(f\"💾 Torch using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
        "    print(f\"🧠 Total rows in full tft_df: {len(tft_df)}\")\n",
        "\n",
        "\n",
        "    run_dir = os.path.join(train_config[\"output_base_dir\"], f\"{target}_run\")\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    train_df = tft_df[tft_df.time_idx <= tft_df['time_idx'].max() * 0.8].copy()\n",
        "    train_df = train_df[np.isfinite(train_df[target])]\n",
        "    train_df = train_df.dropna(subset=[target])\n",
        "    bad_rows = tft_df[~np.isfinite(tft_df[target]) | tft_df[target].isna()]\n",
        "    print(f\"⚠️ {len(bad_rows)} bad rows removed for target: {target}\")\n",
        "\n",
        "    # Dataset\n",
        "    dataset = TimeSeriesDataSet(\n",
        "        train_df,\n",
        "        time_idx='time_idx',\n",
        "        target=target,\n",
        "        group_ids=train_config[\"group_ids\"],\n",
        "        max_encoder_length=train_config[\"max_encoder_length\"],\n",
        "        max_prediction_length=train_config[\"max_prediction_length\"],\n",
        "        time_varying_known_reals=train_config[\"time_varying_known_reals\"],\n",
        "        time_varying_unknown_reals=train_config[\"targets\"],\n",
        "        target_normalizer=GroupNormalizer(groups=train_config[\"group_ids\"]),\n",
        "        add_relative_time_idx=True,\n",
        "        add_target_scales=True,\n",
        "        add_encoder_length=True,\n",
        "        allow_missing_timesteps=True\n",
        "    )\n",
        "\n",
        "    val_dataset = TimeSeriesDataSet.from_dataset(dataset, tft_df, predict=True, stop_randomization=True, allow_missing_timesteps=True)\n",
        "\n",
        "    train_dataloader = dataset.to_dataloader(train=True, batch_size=train_config[\"batch_size\"], num_workers=0)\n",
        "    val_dataloader = val_dataset.to_dataloader(train=False, batch_size=train_config[\"batch_size\"], num_workers=0)\n",
        "\n",
        "    # Logger and checkpoint\n",
        "    logger = CSVLogger(save_dir=train_config[\"log_dir\"], name=f\"{target}_log\")\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        monitor=\"val_loss\",\n",
        "        dirpath=run_dir,\n",
        "        filename=\"tft-{epoch:02d}-{val_loss:.2f}\",\n",
        "        save_top_k=1,\n",
        "        save_last=True,\n",
        "        mode=\"min\"\n",
        "    )\n",
        "\n",
        "    # Load or create model\n",
        "    ckpt_path = os.path.join(run_dir, \"tft-last.ckpt\")\n",
        "    if os.path.exists(ckpt_path):\n",
        "        print(f\"📦 Resuming from checkpoint: {ckpt_path}\")\n",
        "        model = TemporalFusionTransformer.load_from_checkpoint(\n",
        "            checkpoint_path=ckpt_path,\n",
        "            dataset=dataset,\n",
        "            loss=train_config[\"loss_fn\"]\n",
        "        )\n",
        "    else:\n",
        "        print(\"🆕 Starting new model\")\n",
        "        model = TemporalFusionTransformer.from_dataset(\n",
        "            dataset,\n",
        "            learning_rate=train_config[\"learning_rate\"],\n",
        "            hidden_size=train_config[\"hidden_size\"],\n",
        "            dropout=train_config[\"dropout\"],\n",
        "            loss=train_config[\"loss_fn\"],\n",
        "            log_interval=10,\n",
        "            reduce_on_plateau_patience=4,\n",
        "        )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        max_epochs=train_config[\"epochs\"],\n",
        "        accelerator=[\"accelerator_opt\"],\n",
        "        devices=1 if torch.cuda.is_available() else None,\n",
        "        logger=logger,\n",
        "        callbacks=[checkpoint_callback],\n",
        "        enable_checkpointing=True\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
        "\n",
        "    # Predict\n",
        "    predictions, x = model.predict(val_dataloader, mode='raw', return_x=True)\n",
        "    forecast = predictions['prediction'][0].detach().cpu().numpy()\n",
        "\n",
        "    # Plot and save\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    model.plot_prediction(x, predictions, idx=0, show_future_observed=True)\n",
        "    plt.title(f\"Prediction Plot for {target}\")\n",
        "    plt.savefig(f\"{run_dir}/plot.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Save predictions\n",
        "    pd.DataFrame(forecast, columns=[f'{target}_forecast']).to_csv(f\"{run_dir}/predictions.csv\", index=False)\n",
        "\n",
        "    # Save loss log\n",
        "    log_csv_path = os.path.join(logger.log_dir, \"metrics.csv\")\n",
        "    if os.path.exists(log_csv_path):\n",
        "        shutil.copy(log_csv_path, f\"{run_dir}/loss_log.csv\")\n",
        "\n",
        "    # Save parameters\n",
        "    with open(f\"{run_dir}/params.json\", \"w\") as f:\n",
        "        json.dump(train_config, f, indent=2)\n",
        "\n",
        "    # Save notes with spikes info\n",
        "    spikes = forecast > np.percentile(forecast, 95)\n",
        "    with open(f\"{run_dir}/notes.txt\", \"w\") as f:\n",
        "        f.write(f\"Target: {target}\\n\")\n",
        "        f.write(f\"Spikes > 95th percentile: {int(spikes.sum())}\\n\")\n",
        "        f.write(\"Review plot.png and predictions.csv for further insights.\\n\")\n",
        "\n",
        "    print(f\"✅ Run complete — outputs saved at: {run_dir}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.12 ('forecasting_env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2133a3972b28273c10fa027bbde5fb58efc69f3a1cd517826cf4b1affadfce4e"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}