{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swaraj0009/AI_Models/blob/master/TFT/notebooks/4_ttf_resource_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drive Loading"
      ],
      "metadata": {
        "id": "Zut3EaByhFTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9imFCsDrwtVO",
        "outputId": "130f11d4-59f7-4807-af52-8f2599f1c74f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "is7xTtSYgp0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚ö° Quick Setup - Run after runtime reset (CPU/GPU Switch)\n",
        "# Installs essential packages silently to save output clutter\n",
        "\n",
        "!pip install dask pytz torch pytorch-forecasting pytorch-lightning \\\n",
        "    rich colorama matplotlib seaborn pandas numpy tensorboard \\\n",
        "    'lightning[extra]' pyarrow fastparquet --quiet > /dev/null\n",
        "\n",
        "print(\"\\033[92m‚úÖ All required packages installed successfully.\\033[0m\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9TAeg3MxRMV",
        "outputId": "9331f395-ded5-484d-ffc6-9d3547ed54e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m‚úÖ All required packages installed successfully.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "MEIX0ouRhGwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zMD5usllwmtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "170e0f94-db42-4aac-f01a-382e8d8ac5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Libraries are loaded : 20250707-031228\n",
            "‚ö° Using device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Standard Library\n",
        "import os\n",
        "import datetime\n",
        "import glob\n",
        "import json\n",
        "import shutil\n",
        "import math\n",
        "import pytz\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Third-Party Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "\n",
        "# PyTorch Lightning\n",
        "# from datetime import datetime\n",
        "import pytorch_forecasting\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# PyTorch Forecasting\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "from pytorch_forecasting.data import NaNLabelEncoder\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_forecasting.data.encoders import GroupNormalizer\n",
        "\n",
        "\n",
        "ist = pytz.timezone('Asia/Kolkata')\n",
        "now_ist = datetime.datetime.now(ist)\n",
        "timestamp = now_ist.strftime(\"%Y%m%d-%H%M%S\")\n",
        "print(f\"All Libraries are loaded : {timestamp}\")\n",
        "\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚ö° Using device: {device.upper()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Configurable Parameters"
      ],
      "metadata": {
        "id": "YsYJkzavg7c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data path & VM selection\n",
        "parquet_path = \"/content/drive/MyDrive/datasets/processed/FeatureEng_full_streak.parquet\"\n",
        "\n",
        "# Model training parameters\n",
        "train_config = {\n",
        "    # üéØ Prediction Targets\n",
        "\n",
        "    # [\n",
        "    #     \"cpu_utilization_ratio\",\n",
        "    #     \"memory_utilization_ratio\",\n",
        "    #     \"disk_total_throughput\",\n",
        "    #     \"network_total_throughput\"\n",
        "    # ],\n",
        "\n",
        "    \"targets\": [\"cpu_utilization_ratio\"],\n",
        "\n",
        "    # üìÖ Known time-dependent features (known at prediction time)\n",
        "    \"time_varying_known_reals\": [\n",
        "        \"time_idx\",\n",
        "        \"hour\", \"day\", \"dayofweek\", \"month\", \"is_weekend\",\n",
        "        \"hour_sin\", \"hour_cos\",\n",
        "        \"dayofweek_sin\", \"dayofweek_cos\",\n",
        "        \"month_sin\", \"month_cos\"\n",
        "    ],\n",
        "\n",
        "    # üìà Features only known up to current timestep (future unknown)\n",
        "    \"time_varying_unknown_reals\": [\n",
        "        \"cpu_util_prev\", \"cpu_util_diff\",\n",
        "        \"memory_util_prev\", \"memory_util_diff\",\n",
        "        \"network_total_prev\", \"network_total_diff\",\n",
        "        \"disk_write_prev\", \"disk_write_diff\",\n",
        "        \"disk_rolling_mean\", \"network_rolling_mean\"\n",
        "    ],\n",
        "\n",
        "    # üîê Grouping feature\n",
        "    \"group_ids\": [\"vm_id\"],\n",
        "\n",
        "    # üß† Sequence lengths (adjust based on resources)\n",
        "    \"max_encoder_length\": 5000,      # input length\n",
        "    \"max_prediction_length\": 3000,     # forecast horizon\n",
        "\n",
        "    # ‚öôÔ∏è Model Hyperparameters (tune later)\n",
        "    \"hidden_size\": 16,\n",
        "    \"dropout\": 0.2,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"batch_size\": 4,\n",
        "    \"num_workers\": 2,\n",
        "\n",
        "    # üõë Early stopping\n",
        "    \"early_stopping_patience\": 5,\n",
        "    \"epochs\": 10,\n",
        "\n",
        "    # üßÆ Loss function\n",
        "    \"loss_fn\": RMSE(),\n",
        "\n",
        "    # üíæ Output paths\n",
        "    \"output_base_dir\": \"/content/drive/MyDrive/output\",\n",
        "    \"log_dir\": \"/content/drive/MyDrive/output/logs\"\n",
        "}"
      ],
      "metadata": {
        "id": "Y4lrYzgxwbLr"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = pd.read_parquet(parquet_path)\n",
        "\n",
        "print(f\"‚úÖ Loaded data shape: {df5.shape}\")\n",
        "print(f\"üî¢ Unique VMs: {df5['vm_id'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj81xFUJjf_1",
        "outputId": "bb32a2bf-8319-4ab2-b7cf-2a4dc3be4d2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded data shape: (6487138, 38)\n",
            "üî¢ Unique VMs: 751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by VM and count how many time steps each VM has\n",
        "vm_streaks = df5.groupby(\"vm_id\").agg(\n",
        "    total_points=(\"time_idx\", \"count\"),\n",
        "    max_time_idx=(\"time_idx\", \"max\")\n",
        ").reset_index()\n",
        "\n",
        "# Sort by total_points (or max_time_idx) descending\n",
        "top_200_vms = vm_streaks.sort_values(by=\"total_points\", ascending=False).head(200)[\"vm_id\"]\n",
        "\n",
        "print(f\"‚úÖ Selected top 200 VMs with longest data streaks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybFhjPlCj2i8",
        "outputId": "a7facab2-c994-4663-f2da-056919320b71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Selected top 200 VMs with longest data streaks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VM Configure"
      ],
      "metadata": {
        "id": "iIP9NMkMhW4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter original DataFrame for these 200 VMs\n",
        "df6 = df5[df5[\"vm_id\"].isin(top_200_vms)].copy()\n",
        "print(f\"‚úÖ Filtered data shape (top 200 VMs): {df6.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6stdAQxokYhP",
        "outputId": "5b9712bd-822c-4627-cf54-349dee076d8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Filtered data shape (top 200 VMs): (1727600, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"üéØ VMs in final dataset: {df6['vm_id'].nunique()}\")  # Should be 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OglSlB95k1f8",
        "outputId": "fa088f3a-0bab-4f27-df77-bc25323052e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ VMs in final dataset: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Columns Filter"
      ],
      "metadata": {
        "id": "rDSk5HS0iVcy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JpDH8N3TwmtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f746d5b-a91f-44e1-8ca9-1bdfa002cf52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Columns after filtering: 25\n",
            "\u001b[94m‚ÑπÔ∏è Clean DataFrame ‚Üí Columns: 25 | Shape: (1727600, 25)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Drop unused columns based on train_config\n",
        "columns_to_keep = (\n",
        "    train_config[\"time_varying_known_reals\"]\n",
        "    + train_config[\"time_varying_unknown_reals\"]\n",
        "    + train_config[\"targets\"]\n",
        "    + train_config[\"group_ids\"]\n",
        "    + ['time_idx', 'timestamp']\n",
        ")\n",
        "\n",
        "# üîÅ Remove duplicates in case of overlaps\n",
        "columns_to_keep = list(set(columns_to_keep))\n",
        "\n",
        "# üìâ Filter DataFrame\n",
        "df6 = df6[columns_to_keep]\n",
        "\n",
        "print(f\"‚úÖ Columns after filtering: {len(df6.columns)}\")\n",
        "\n",
        "# üßº Optimize category column\n",
        "if \"vm_id\" in df6.columns:\n",
        "    df6[\"vm_id\"] = df6[\"vm_id\"].astype(\"category\")\n",
        "    df6[\"vm_id\"] = df6[\"vm_id\"].cat.remove_unused_categories()\n",
        "\n",
        "print(f\"\\033[94m‚ÑπÔ∏è Clean DataFrame ‚Üí Columns: {len(df6.columns)} | Shape: {df6.shape}\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Logic with Reset Index"
      ],
      "metadata": {
        "id": "7lxANWba7IRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.51\n",
        "\n",
        "train_df_list = []\n",
        "val_df_list = []\n",
        "\n",
        "for vm_id, group in df6.groupby(\"vm_id\",observed=False):\n",
        "    group = group.sort_values(\"time_idx\")\n",
        "    split_idx = int(len(group) * train_ratio)\n",
        "\n",
        "    train_df_list.append(group.iloc[:split_idx])\n",
        "    val_df_list.append(group.iloc[split_idx:])\n",
        "\n",
        "# Combine all\n",
        "train_df = pd.concat(train_df_list).reset_index(drop=True)\n",
        "val_df = pd.concat(val_df_list).reset_index(drop=True)\n",
        "\n",
        "print(f\"‚úÖ Train shape: {train_df.shape}\")\n",
        "print(f\"‚úÖ Val shape: {val_df.shape}\")"
      ],
      "metadata": {
        "id": "pEgkRazj7DZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f401aa76-8017-4afd-f390-50b7f4485dfa"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Train shape: (881000, 25)\n",
            "‚úÖ Val shape: (846600, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre validation check for split for Encoder & prediction"
      ],
      "metadata": {
        "id": "ZYOMUIIL7gi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define required steps\n",
        "required_train_steps = train_config[\"max_encoder_length\"] + train_config[\"max_prediction_length\"]\n",
        "required_val_steps = train_config[\"max_prediction_length\"]\n",
        "\n",
        "# Step 2: Get the split point\n",
        "max_time_idx = df6[\"time_idx\"].max()\n",
        "split_point = int(max_time_idx * train_ratio)\n",
        "\n",
        "# Step 3: Split data\n",
        "train_df = df6[df6[\"time_idx\"] <= split_point].copy()\n",
        "val_df = df6[df6[\"time_idx\"] > split_point].copy()\n",
        "\n",
        "# Step 4: Validate VMs having enough time points\n",
        "vm_train_counts = train_df.groupby(\"vm_id\",observed=False)[\"time_idx\"].nunique()\n",
        "vm_val_counts = val_df.groupby(\"vm_id\",observed=False)[\"time_idx\"].nunique()\n",
        "\n",
        "# Step 5: Filter valid VMs\n",
        "valid_train_vms = vm_train_counts[vm_train_counts >= required_train_steps].index\n",
        "valid_val_vms = vm_val_counts[vm_val_counts >= required_val_steps].index\n",
        "\n",
        "# Step 6: Filter DataFrames\n",
        "train_df = train_df[train_df[\"vm_id\"].isin(valid_train_vms)].copy()\n",
        "val_df = val_df[val_df[\"vm_id\"].isin(valid_val_vms)].copy()\n",
        "\n",
        "# Step 7: Summary\n",
        "print(\"\\nüìä VM-Level Split Window Check\\n\")\n",
        "print(f\"‚úÖ VMs valid for training   : {len(valid_train_vms)} / {vm_train_counts.shape[0]}\")\n",
        "print(f\"‚úÖ VMs valid for validation : {len(valid_val_vms)} / {vm_val_counts.shape[0]}\")"
      ],
      "metadata": {
        "id": "4fLQyI2hqd-_",
        "outputId": "132579d8-fd54-4eeb-b1ea-93405ecabad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä VM-Level Split Window Check\n",
            "\n",
            "‚úÖ VMs valid for training   : 200 / 200\n",
            "‚úÖ VMs valid for validation : 200 / 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Configuration"
      ],
      "metadata": {
        "id": "opiXlao30zOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_encoder_length = train_config[\"max_encoder_length\"]\n",
        "max_prediction_length = train_config[\"max_prediction_length\"]\n",
        "group_ids = train_config[\"group_ids\"]\n",
        "targets = train_config[\"targets\"]  # e.g., [\"cpu_utilization_ratio\"]\n",
        "time_varying_known_reals = train_config[\"time_varying_known_reals\"]\n",
        "time_varying_unknown_reals = train_config[\"time_varying_unknown_reals\"]\n",
        "batchsize = train_config[\"batch_size\"]\n",
        "numworkers = train_config[\"num_workers\"]\n",
        "learningrate = train_config[\"learning_rate\"]\n",
        "hiddensize = train_config[\"hidden_size\"]\n",
        "lossfn = train_config[\"loss_fn\"]\n",
        "dropout = train_config[\"dropout\"]"
      ],
      "metadata": {
        "id": "MBHvjTvw0wNN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TimeSeriesDataSet"
      ],
      "metadata": {
        "id": "zs0rxyuQuH1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Dataset\n",
        "tft_dataset = TimeSeriesDataSet(\n",
        "    train_df,\n",
        "    time_idx=\"time_idx\",\n",
        "    target=targets[0],  # Start with first target (e.g., \"cpu_utilization_ratio\")\n",
        "    group_ids=group_ids,\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    time_varying_known_reals=time_varying_known_reals,\n",
        "    time_varying_unknown_reals=time_varying_unknown_reals,\n",
        "    static_categoricals=[],\n",
        "    static_reals=[],\n",
        "    target_normalizer=GroupNormalizer(groups=group_ids),\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    add_encoder_length=True,\n",
        ")\n",
        "\n",
        "val_dataset = tft_dataset.from_dataset(\n",
        "    tft_dataset,\n",
        "    val_df,\n",
        "    predict=True,\n",
        "    stop_randomization=True\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = tft_dataset.to_dataloader(train=True, batch_size=batchsize, num_workers=numworkers)\n",
        "val_dataloader = val_dataset.to_dataloader(train=False, batch_size=batchsize, num_workers=numworkers)"
      ],
      "metadata": {
        "id": "RkrZt4FfzkVZ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output & Log Folder Creation"
      ],
      "metadata": {
        "id": "BoJ1pukZhskL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Short name for target\n",
        "def get_short_target_name(targets):\n",
        "    short_map = {\n",
        "        \"cpu_utilization_ratio\": \"cpu\",\n",
        "        \"memory_utilization_ratio\": \"mem\",\n",
        "        \"disk_total_throughput\": \"disk\",\n",
        "        \"network_total_throughput\": \"net\"\n",
        "    }\n",
        "    if isinstance(targets, list) and targets:\n",
        "        return short_map.get(targets[0], targets[0][:3])\n",
        "    return \"unknown\"\n",
        "\n",
        "# Step 2: Folder naming using extracted vars\n",
        "def get_run_folder_name(vm_count):\n",
        "    return \"_\".join([\n",
        "        get_short_target_name(targets),\n",
        "        f\"{vm_count}vms\",\n",
        "        f\"past{max_encoder_length}\",\n",
        "        f\"fut{max_prediction_length}\",\n",
        "        f\"bs{batchsize}\",\n",
        "        f\"lr{learningrate:.0e}\".replace('+0', ''),\n",
        "        f\"hid{hiddensize}\",\n",
        "        timestamp\n",
        "    ])\n",
        "\n",
        "# Step 3: Build folder name\n",
        "vm_count = df6[\"vm_id\"].nunique() # Calculate vm_count from df6\n",
        "folder_name = get_run_folder_name(vm_count)\n",
        "train_config[\"output_base_dir\"] = os.path.join(train_config[\"output_base_dir\"], folder_name)\n",
        "train_config[\"log_dir\"] = os.path.join(train_config[\"log_dir\"], folder_name)\n",
        "\n",
        "# Step 4: Create folders\n",
        "os.makedirs(train_config[\"output_base_dir\"], exist_ok=True)\n",
        "os.makedirs(train_config[\"log_dir\"], exist_ok=True)\n",
        "\n",
        "# Step 5: Print summary\n",
        "print(\"‚úÖ Output directory:\", train_config[\"output_base_dir\"])\n",
        "print(\"‚úÖ Log directory   :\", train_config[\"log_dir\"])"
      ],
      "metadata": {
        "id": "Ib5yqZQz-9PZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4777c914-7eeb-414b-f9d4-03b59cc7764c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Output directory: /content/drive/MyDrive/output/cpu_200vms_past2100_fut2100_bs4_lr1e-03_hid16_20250707-030926\n",
            "‚úÖ Log directory   : /content/drive/MyDrive/output/logs/cpu_200vms_past2100_fut2100_bs4_lr1e-03_hid16_20250707-030926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tft_df = df6.copy()"
      ],
      "metadata": {
        "id": "uLNBdCq_YWb6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging & Callbacks"
      ],
      "metadata": {
        "id": "tLG5FXgbvkJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Use your existing function\n",
        "def get_short_target_name_single(target):\n",
        "    short_map = {\n",
        "        \"cpu_utilization_ratio\": \"cpu\",\n",
        "        \"memory_utilization_ratio\": \"mem\",\n",
        "        \"disk_total_throughput\": \"disk\",\n",
        "        \"network_total_throughput\": \"net\"\n",
        "    }\n",
        "    if isinstance(targets, list) and targets:\n",
        "        return short_map.get(targets[0], targets[0][:3])\n",
        "    return \"unknown\"\n",
        "\n",
        "for target in targets:\n",
        "    short_target = get_short_target_name_single(target)  # ‚úÖ Now uses each target in loop\n",
        "\n",
        "    print(f\"\\nüîÅ Training for target: {target}\")\n",
        "\n",
        "    run_dir = os.path.join(train_config[\"output_base_dir\"], f\"{short_target}_run_{timestamp}\")\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    tft_df.to_csv(os.path.join(run_dir, \"tft_df.csv\"), index=False)\n",
        "    tft_dataset.save(os.path.join(run_dir, \"tft_df_metadata\"))\n",
        "\n",
        "    meta_cols = ['vm_id', 'timestamp', 'time_idx']\n",
        "    if all(col in val_df.columns for col in meta_cols):\n",
        "        meta_df = val_df[meta_cols].reset_index(drop=True)\n",
        "        meta_df.to_csv(os.path.join(run_dir, \"forecast_metadata.csv\"), index=False)\n",
        "        print(f\"‚úÖ Metadata saved to: {run_dir}/forecast_metadata.csv\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping metadata save ‚Äî missing columns: {meta_cols}\")\n",
        "\n",
        "    logger = CSVLogger(\n",
        "        save_dir=train_config[\"log_dir\"],\n",
        "        name=f\"{short_target}_log\"  # ‚úÖ Each log is now uniquely named per target\n",
        "    )\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        monitor=\"val_loss\",\n",
        "        dirpath=run_dir,\n",
        "        filename=\"tft-{epoch:02d}-{val_loss:.2f}\",\n",
        "        save_top_k=1,\n",
        "        save_last=True,\n",
        "        mode=\"min\"\n",
        "    )\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=train_config[\"early_stopping_patience\"],\n",
        "        mode=\"min\"\n",
        "    )"
      ],
      "metadata": {
        "id": "X07NZKn0SeUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9e5df4-280a-4168-9bee-0fa9e16c0f55"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Training for target: cpu_utilization_ratio\n",
            "‚úÖ Metadata saved to: /content/drive/MyDrive/output/cpu_200vms_past2100_fut2100_bs4_lr1e-03_hid16_20250707-030926/cpu_run_20250707-030926/forecast_metadata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model, Lightning, Trainer"
      ],
      "metadata": {
        "id": "XuuT4XcivziV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚ö° Using device: {device.upper()}\")\n",
        "\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from pytorch_forecasting.models import TemporalFusionTransformer\n",
        "\n",
        "class TFTLightningModule(pl.LightningModule):\n",
        "    def __init__(self, tft_model: TemporalFusionTransformer, learning_rate: float, loss_fn: torch.nn.Module):\n",
        "        super().__init__()\n",
        "        self.tft_model = tft_model\n",
        "        self.learning_rate = learning_rate\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.tft_model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat.prediction, y)\n",
        "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat.prediction, y)\n",
        "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "# Create the TFT model\n",
        "tft_model = TemporalFusionTransformer.from_dataset(\n",
        "    tft_dataset,\n",
        "    learning_rate=train_config[\"learning_rate\"],\n",
        "    hidden_size=train_config[\"hidden_size\"],\n",
        "    dropout=train_config[\"dropout\"],\n",
        "    loss=train_config[\"loss_fn\"],\n",
        "    log_interval=10,\n",
        "    reduce_on_plateau_patience=4\n",
        ")\n",
        "\n",
        "# Wrap the TFT model in a LightningModule\n",
        "model = TFTLightningModule(\n",
        "    tft_model=tft_model,\n",
        "    learning_rate=train_config[\"learning_rate\"],\n",
        "    loss_fn=train_config[\"loss_fn\"]\n",
        ")\n",
        "\n",
        "# Setup Trainer\n",
        "if torch.cuda.is_available():\n",
        "    accelerator = \"gpu\"\n",
        "    devices = 1\n",
        "else:\n",
        "    accelerator = \"cpu\"\n",
        "    devices = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=train_config[\"epochs\"],\n",
        "    accelerator=accelerator,\n",
        "    devices=devices,\n",
        "    logger=logger,\n",
        "    callbacks=[checkpoint_callback, early_stopping],\n",
        "    enable_checkpointing=True\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718,
          "referenced_widgets": [
            "d0c2b4f794e14287adab1ebefcf52eac",
            "99dc3b04f8324e5a808f27a85f01d13d",
            "22a6151dd9fa4f759850b06ac783872d",
            "a460764d9647468ebd2a3ad7d8ab19a6",
            "9e9a2fb59354420298addc4e41bd612a",
            "fb528ea772b648bcb2ee7e5cd4f00e4a",
            "f2421ec4f90b4bf4ae921e0b2220a6bf",
            "12754e87e89d4a30a982f2b3da878fc7",
            "cb015f628da24e4ca863fe48ebd9088a",
            "7fe08a94b0e9455f8cec0a3910c92390",
            "90ef17397f2546458eba3eb1ac62ef9e"
          ]
        },
        "id": "Rqv7jTfcnEfY",
        "outputId": "4dff5f61-e968-46f8-b4bf-0c86741917c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Using device: CUDA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name      | Type                      | Params | Mode \n",
            "----------------------------------------------------------------\n",
            "0 | tft_model | TemporalFusionTransformer | 40.8 K | train\n",
            "1 | loss_fn   | RMSE                      | 0      | eval \n",
            "----------------------------------------------------------------\n",
            "40.8 K    Trainable params\n",
            "0         Non-trainable params\n",
            "40.8 K    Total params\n",
            "0.163     Total estimated model params size (MB)\n",
            "733       Modules in train mode\n",
            "1         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c2b4f794e14287adab1ebefcf52eac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'to'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20-271837476.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         )\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-20-271837476.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actual vs Prediction Graphs"
      ],
      "metadata": {
        "id": "YAkb7l6BytSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÆ Step 1: Make raw predictions on validation set\n",
        "prediction_output = model.tft_model.predict(\n",
        "    val_dataloader, mode='raw', return_x=True\n",
        ")\n",
        "\n",
        "# ‚úÖ Step 2: Extract input and output\n",
        "x = prediction_output[\"x\"]\n",
        "predictions = prediction_output[\"output\"]\n",
        "\n",
        "# ‚úÖ Step 3: Extract forecast values as numpy array (for CSV export)\n",
        "forecast = predictions[\"prediction\"].detach().cpu().numpy()\n",
        "\n",
        "# ‚úÖ Step 4: Plot forecast using built-in TFT visualization\n",
        "fig = model.tft_model.plot_prediction(\n",
        "    x, predictions, idx=0, show_future_observed=True\n",
        ")\n",
        "plt.title(f\"Prediction Plot for {target}\")\n",
        "\n",
        "# ‚úÖ Reduce legend size and move it neatly outside\n",
        "plt.legend(\n",
        "    loc='upper left',\n",
        "    bbox_to_anchor=(1, 1),\n",
        "    fontsize='small',\n",
        "    frameon=True\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# ‚úÖ Step 5: Save the plot as PNG\n",
        "plt.savefig(f\"{run_dir}/plot.png\", bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"‚úÖ Prediction plot saved at: {run_dir}/plot.png\")\n",
        "\n",
        "# ‚úÖ Step 6: Save forecast to CSV\n",
        "pd.DataFrame(forecast, columns=[f'{target}_forecast']).to_csv(\n",
        "    f\"{run_dir}/predictions.csv\", index=False\n",
        ")\n",
        "print(f\"‚úÖ Forecast values saved to: {run_dir}/predictions.csv\")"
      ],
      "metadata": {
        "id": "B2qLHzHdywHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spike Detection & Save Metadata"
      ],
      "metadata": {
        "id": "Wp2UKawDwVRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Ensure forecast is a NumPy array\n",
        "if isinstance(forecast, torch.Tensor):\n",
        "    forecast = forecast.detach().cpu().numpy()\n",
        "elif isinstance(forecast, pd.Series):\n",
        "    forecast = forecast.values\n",
        "else:\n",
        "    forecast = np.array(forecast)\n",
        "\n",
        "# Detect spikes above the 95th percentile\n",
        "spikes = forecast > np.percentile(forecast, 95)\n",
        "spike_count = int(spikes.sum())\n",
        "\n",
        "# üîπ Save notes.txt with target name and spike info\n",
        "notes_path = os.path.join(run_dir, \"notes.txt\")\n",
        "with open(notes_path, \"w\") as f:\n",
        "    f.write(f\"Target: {target}\\n\")\n",
        "    f.write(f\"Spikes > 95th percentile: {spike_count}\\n\")\n",
        "    f.write(\"Review plot.png and predictions.csv for further insights.\\n\")\n",
        "\n",
        "print(f\"üìÑ Notes saved at: {notes_path}\")\n",
        "\n",
        "# üîπ Prepare train_config for JSON (remove non-serializable objects)\n",
        "serializable_train_config = train_config.copy()\n",
        "serializable_train_config[\"loss_fn\"] = serializable_train_config[\"loss_fn\"].__class__.__name__\n",
        "\n",
        "# üîπ Save model config as JSON\n",
        "config_path = os.path.join(run_dir, \"modelconfig.json\")\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(serializable_train_config, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Config saved at: {config_path}\")\n",
        "print(f\"‚úÖ Run complete. Outputs saved at: {run_dir}\")\n",
        "\n",
        "forecast_path = os.path.join(run_dir, \"predictions.csv\")\n",
        "forecast_df.to_csv(forecast_path, index=False)\n",
        "print(f\"‚úÖ Forecast values saved to: {forecast_path}\")"
      ],
      "metadata": {
        "id": "ZZViKR3poBY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5iELq2nboDno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k9bYj41m4Dc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmkEnl8nF--f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2133a3972b28273c10fa027bbde5fb58efc69f3a1cd517826cf4b1affadfce4e"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0c2b4f794e14287adab1ebefcf52eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99dc3b04f8324e5a808f27a85f01d13d",
              "IPY_MODEL_22a6151dd9fa4f759850b06ac783872d",
              "IPY_MODEL_a460764d9647468ebd2a3ad7d8ab19a6"
            ],
            "layout": "IPY_MODEL_9e9a2fb59354420298addc4e41bd612a"
          }
        },
        "99dc3b04f8324e5a808f27a85f01d13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb528ea772b648bcb2ee7e5cd4f00e4a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f2421ec4f90b4bf4ae921e0b2220a6bf",
            "value": "Sanity‚ÄáChecking‚ÄáDataLoader‚Äá0:‚Äá‚Äá‚Äá0%"
          }
        },
        "22a6151dd9fa4f759850b06ac783872d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12754e87e89d4a30a982f2b3da878fc7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb015f628da24e4ca863fe48ebd9088a",
            "value": 0
          }
        },
        "a460764d9647468ebd2a3ad7d8ab19a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fe08a94b0e9455f8cec0a3910c92390",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_90ef17397f2546458eba3eb1ac62ef9e",
            "value": "‚Äá0/2‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "9e9a2fb59354420298addc4e41bd612a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "fb528ea772b648bcb2ee7e5cd4f00e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2421ec4f90b4bf4ae921e0b2220a6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12754e87e89d4a30a982f2b3da878fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb015f628da24e4ca863fe48ebd9088a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fe08a94b0e9455f8cec0a3910c92390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ef17397f2546458eba3eb1ac62ef9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}