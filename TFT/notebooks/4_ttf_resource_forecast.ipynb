{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swaraj0009/AI_Models/blob/master/TFT/notebooks/4_ttf_resource_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drive Loading"
      ],
      "metadata": {
        "id": "Zut3EaByhFTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9imFCsDrwtVO",
        "outputId": "76191524-0af5-43df-f881-a149ba776f79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "is7xTtSYgp0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âš¡ Quick Setup - Run after runtime reset (CPU/GPU Switch)\n",
        "# Installs essential packages silently to save output clutter\n",
        "\n",
        "!pip install dask pytz torch pytorch-forecasting pytorch-lightning \\\n",
        "    rich colorama matplotlib seaborn pandas numpy tensorboard \\\n",
        "    'lightning[extra]' pyarrow fastparquet --quiet > /dev/null\n",
        "\n",
        "print(\"\\033[92mâœ… All required packages installed successfully.\\033[0m\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9TAeg3MxRMV",
        "outputId": "2480e7e1-fcaf-4822-c729-5a79ed97557b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mâœ… All required packages installed successfully.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "MEIX0ouRhGwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zMD5usllwmtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36eab99-d5a9-47da-c573-eff88fe6d725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Libraries are loaded : 20250706-215111\n"
          ]
        }
      ],
      "source": [
        "# Standard Library\n",
        "import os\n",
        "import datetime\n",
        "import glob\n",
        "import json\n",
        "import shutil\n",
        "import math\n",
        "import pytz\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Third-Party Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "\n",
        "# PyTorch Lightning\n",
        "# from datetime import datetime\n",
        "import pytorch_forecasting\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# PyTorch Forecasting\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "\n",
        "ist = pytz.timezone('Asia/Kolkata')\n",
        "now_ist = datetime.datetime.now(ist)\n",
        "timestamp = now_ist.strftime(\"%Y%m%d-%H%M%S\")\n",
        "print(f\"All Libraries are loaded : {timestamp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Configurable Parameters"
      ],
      "metadata": {
        "id": "YsYJkzavg7c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data path & VM selection\n",
        "parquet_path = \"/content/drive/MyDrive/datasets/processed/FeatureEng_full_streak.parquet\"\n",
        "\n",
        "# e.g., 50, 100, 250 etc.\n",
        "num_vms_to_load = 200\n",
        "\n",
        "# Model training parameters\n",
        "train_config = {\n",
        "    # ðŸŽ¯ Prediction Targets\n",
        "    \"targets\": [\n",
        "        \"cpu_utilization_ratio\",\n",
        "        \"memory_utilization_ratio\",\n",
        "        \"disk_total_throughput\",\n",
        "        \"network_total_throughput\"\n",
        "    ],\n",
        "\n",
        "    # ðŸ“… Known time-dependent features (known at prediction time)\n",
        "    \"time_varying_known_reals\": [\n",
        "        \"time_idx\",\n",
        "        \"hour\", \"day\", \"dayofweek\", \"month\", \"is_weekend\",\n",
        "        \"hour_sin\", \"hour_cos\",\n",
        "        \"dayofweek_sin\", \"dayofweek_cos\",\n",
        "        \"month_sin\", \"month_cos\"\n",
        "    ],\n",
        "\n",
        "    # ðŸ“ˆ Features only known up to current timestep (future unknown)\n",
        "    \"time_varying_unknown_reals\": [\n",
        "        \"cpu_util_prev\", \"cpu_util_diff\",\n",
        "        \"memory_util_prev\", \"memory_util_diff\",\n",
        "        \"network_total_prev\", \"network_total_diff\",\n",
        "        \"disk_write_prev\", \"disk_write_diff\",\n",
        "        \"disk_rolling_mean\", \"network_rolling_mean\"\n",
        "    ],\n",
        "\n",
        "    # ðŸ” Grouping feature\n",
        "    \"group_ids\": [\"vm_id\"],\n",
        "\n",
        "    # ðŸ§  Sequence lengths (adjust based on resources)\n",
        "    \"max_encoder_length\": 2016,      # input length\n",
        "    \"max_prediction_length\": 96,     # forecast horizon\n",
        "\n",
        "    # âš™ï¸ Model Hyperparameters (tune later)\n",
        "    \"hidden_size\": 16,\n",
        "    \"dropout\": 0.2,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"batch_size\": 4,\n",
        "    \"num_workers\": 2,\n",
        "\n",
        "    # ðŸ›‘ Early stopping\n",
        "    \"early_stopping_patience\": 5,\n",
        "    \"epochs\": 10,\n",
        "\n",
        "    # ðŸ§® Loss function\n",
        "    \"loss_fn\": RMSE(),\n",
        "\n",
        "    # ðŸ’¾ Output paths\n",
        "    \"output_base_dir\": \"/content/drive/MyDrive/output\",\n",
        "    \"log_dir\": \"/content/drive/MyDrive/output/logs\"\n",
        "}\n",
        "\n",
        "# VM count for folder naming (update if needed)\n",
        "vm_count = f\"{num_vms_to_load}VMs\""
      ],
      "metadata": {
        "id": "Y4lrYzgxwbLr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = pd.read_parquet(parquet_path)\n",
        "\n",
        "print(f\"âœ… Loaded data shape: {df5.shape}\")\n",
        "print(f\"ðŸ”¢ Unique VMs: {df5['vm_id'].nunique()}\")"
      ],
      "metadata": {
        "id": "Fj81xFUJjf_1",
        "outputId": "93a0aeef-cfcb-4263-a4c5-4155db1d14fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded data shape: (6487138, 38)\n",
            "ðŸ”¢ Unique VMs: 751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by VM and count how many time steps each VM has\n",
        "vm_streaks = df5.groupby(\"vm_id\").agg(\n",
        "    total_points=(\"time_idx\", \"count\"),\n",
        "    max_time_idx=(\"time_idx\", \"max\")\n",
        ").reset_index()\n",
        "\n",
        "# Sort by total_points (or max_time_idx) descending\n",
        "top_200_vms = vm_streaks.sort_values(by=\"total_points\", ascending=False).head(200)[\"vm_id\"]\n",
        "\n",
        "print(f\"âœ… Selected top 200 VMs with longest data streaks.\")"
      ],
      "metadata": {
        "id": "ybFhjPlCj2i8",
        "outputId": "cc5ab7ff-a486-4786-aa8c-6c29b801a2ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Selected top 200 VMs with longest data streaks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VM Configure"
      ],
      "metadata": {
        "id": "iIP9NMkMhW4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter original DataFrame for these 200 VMs\n",
        "df6 = df5[df5[\"vm_id\"].isin(top_200_vms)].copy()\n",
        "print(f\"âœ… Filtered data shape (top 200 VMs): {df6.shape}\")"
      ],
      "metadata": {
        "id": "6stdAQxokYhP",
        "outputId": "70baf94d-3530-4d0d-eeeb-cbe6c8b2c5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Filtered data shape (top 200 VMs): (1727600, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"ðŸŽ¯ VMs in final dataset: {df6['vm_id'].nunique()}\")  # Should be 200"
      ],
      "metadata": {
        "id": "OglSlB95k1f8",
        "outputId": "a9065447-c609-4311-c7e2-b13b48431a9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ VMs in final dataset: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Columns Filter"
      ],
      "metadata": {
        "id": "rDSk5HS0iVcy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JpDH8N3TwmtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1098334-2411-4c1d-d7e5-fafafeb07f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Columns after filtering: 28\n",
            "\u001b[94mâ„¹ï¸ Clean DataFrame â†’ Columns: 28 | Shape: (1727600, 28)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# âœ… Drop unused columns based on train_config\n",
        "columns_to_keep = (\n",
        "    train_config[\"time_varying_known_reals\"]\n",
        "    + train_config[\"time_varying_unknown_reals\"]\n",
        "    + train_config[\"targets\"]\n",
        "    + train_config[\"group_ids\"]\n",
        "    + ['time_idx', 'timestamp']\n",
        ")\n",
        "\n",
        "# ðŸ” Remove duplicates in case of overlaps\n",
        "columns_to_keep = list(set(columns_to_keep))\n",
        "\n",
        "# ðŸ“‰ Filter DataFrame\n",
        "df6 = df6[columns_to_keep]\n",
        "\n",
        "print(f\"âœ… Columns after filtering: {len(df6.columns)}\")\n",
        "\n",
        "# ðŸ§¼ Optimize category column\n",
        "if \"vm_id\" in df6.columns:\n",
        "    df6[\"vm_id\"] = df6[\"vm_id\"].astype(\"category\")\n",
        "    df6[\"vm_id\"] = df6[\"vm_id\"].cat.remove_unused_categories()\n",
        "\n",
        "print(f\"\\033[94mâ„¹ï¸ Clean DataFrame â†’ Columns: {len(df6.columns)} | Shape: {df6.shape}\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 70:30 Split Logic with Reset Index"
      ],
      "metadata": {
        "id": "7lxANWba7IRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.8\n",
        "\n",
        "train_df_list = []\n",
        "val_df_list = []\n",
        "\n",
        "for vm_id, group in df6.groupby(\"vm_id\",observed=False):\n",
        "    group = group.sort_values(\"time_idx\")\n",
        "    split_idx = int(len(group) * train_ratio)\n",
        "\n",
        "    train_df_list.append(group.iloc[:split_idx])\n",
        "    val_df_list.append(group.iloc[split_idx:])\n",
        "\n",
        "# Combine all\n",
        "train_df = pd.concat(train_df_list).reset_index(drop=True)\n",
        "val_df = pd.concat(val_df_list).reset_index(drop=True)\n",
        "\n",
        "print(f\"âœ… Train shape: {train_df.shape}\")\n",
        "print(f\"âœ… Val shape: {val_df.shape}\")"
      ],
      "metadata": {
        "id": "pEgkRazj7DZb",
        "outputId": "ffe3a6b5-bb8c-4abe-c0d7-17a35cb48f12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train shape: (1382000, 28)\n",
            "âœ… Val shape: (345600, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre validation check for split for Encoder & prediction"
      ],
      "metadata": {
        "id": "ZYOMUIIL7gi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Evaluation of time window sufficiency ----\n",
        "\n",
        "max_encoder_length = train_config[\"max_encoder_length\"]\n",
        "max_prediction_length = train_config[\"max_prediction_length\"]\n",
        "\n",
        "# How many unique time_idx values in each split?\n",
        "train_time_steps = train_df['time_idx'].nunique()\n",
        "val_time_steps = val_df['time_idx'].nunique()\n",
        "\n",
        "# Required steps\n",
        "required_train_steps = max_encoder_length + max_prediction_length\n",
        "required_val_steps = max_prediction_length\n",
        "print(\"\\nðŸ“Š Check: Config\\n\")\n",
        "\n",
        "print(f\"ðŸŸ© Max Encoder Length: {max_encoder_length}\")\n",
        "print(f\"ðŸŸ¨ Max Prediction Length: {max_prediction_length}\")\n",
        "print(f\"ðŸŸ© Both Combined: {required_train_steps}\")\n",
        "\n",
        "print(\"\\nðŸ“Š Check: Does the split satisfy the window requirements?\\n\")\n",
        "\n",
        "print(f\"ðŸŸ© Total Row Length: {max_time_idx}\")\n",
        "print(f\"ðŸŸ© Train Time Steps: {train_time_steps} (Required: â‰¥ {required_train_steps})\")\n",
        "print(f\"ðŸŸ¨ Val Time Steps  : {val_time_steps} (Required: â‰¥ {required_val_steps})\")\n",
        "\n",
        "if train_time_steps >= required_train_steps:\n",
        "    print(\"âœ… Training window satisfies requirement.\")\n",
        "else:\n",
        "    print(\"âŒ Training window too short.\")\n",
        "\n",
        "if val_time_steps >= required_val_steps:\n",
        "    print(\"âœ… Validation window satisfies requirement.\")\n",
        "else:\n",
        "    print(\"âŒ Validation window too short.\")\n",
        "\n",
        "\n",
        "# Training needs: max_encoder_length + max_prediction_length\n",
        "# Validation needs: max_prediction_length"
      ],
      "metadata": {
        "id": "4fLQyI2hqd-_",
        "outputId": "3f6c89de-6900-4158-bf4d-89a40bc8ffa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Check: Config\n",
            "\n",
            "ðŸŸ© Max Encoder Length: 2016\n",
            "ðŸŸ¨ Max Prediction Length: 2016\n",
            "ðŸŸ© Both Combined: 4032\n",
            "\n",
            "ðŸ“Š Check: Does the split satisfy the window requirements?\n",
            "\n",
            "ðŸŸ© Total Row Length: 8639\n",
            "ðŸŸ© Train Time Steps: 6047 (Required: â‰¥ 4032)\n",
            "ðŸŸ¨ Val Time Steps  : 2592 (Required: â‰¥ 2016)\n",
            "âœ… Training window satisfies requirement.\n",
            "âœ… Validation window satisfies requirement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variable summary before Modeling"
      ],
      "metadata": {
        "id": "KCszK3G1uwsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# âœ… Step 1: Count time_idx per VM\n",
        "vm_time_lengths = tft_df.groupby(\"vm_id\",observed=False)[\"time_idx\"].nunique().sort_values()\n",
        "\n",
        "# âœ… Step 2: Identify valid VMs\n",
        "valid_vm_ids = vm_time_lengths[vm_time_lengths >= required_train_steps].index\n",
        "invalid_vm_ids = vm_time_lengths[vm_time_lengths < required_train_steps].index\n",
        "\n",
        "# âœ… Step 3: Report summary\n",
        "print(\"\\nðŸ“Š VM Time Index Analysis:\")\n",
        "print(f\"- Total VMs              : {len(vm_time_lengths):,}\")\n",
        "print(f\"- Min steps per VM       : {vm_time_lengths.min()}\")\n",
        "print(f\"- Max steps per VM       : {vm_time_lengths.max()}\")\n",
        "print(f\"- Required per VM        : {required_train_steps}\")\n",
        "print(f\"- âœ… Valid VMs            : {len(valid_vm_ids):,}\")\n",
        "print(f\"- âŒ Invalid VMs          : {len(invalid_vm_ids):,}\")\n",
        "print(f\"- % Valid VMs            : {100 * len(valid_vm_ids) / len(vm_time_lengths):.2f}%\")\n",
        "\n",
        "\n",
        "# âœ… Step 4 (Optional): Filter invalid VMs\n",
        "tft_df = tft_df[tft_df[\"vm_id\"].isin(valid_vm_ids)]\n",
        "\n",
        "# âœ… Step 5 (Optional): Histogram\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(vm_time_lengths, bins=40, kde=False, color=\"steelblue\")\n",
        "plt.axvline(required_train_steps, color=\"red\", linestyle=\"--\", label=f\"min_required={required_train_steps}\")\n",
        "plt.title(\"Time Steps Per VM\")\n",
        "plt.xlabel(\"Time Steps\")\n",
        "plt.ylabel(\"VM Count\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Z-9l7eg5-3j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "a9de0030-b5f5-4672-c160-7df36b233b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š VM Time Index Analysis:\n",
            "- Total VMs              : 200\n",
            "- Min steps per VM       : 1105\n",
            "- Max steps per VM       : 8639\n",
            "- Required per VM        : 4032\n",
            "- âœ… Valid VMs            : 196\n",
            "- âŒ Invalid VMs          : 4\n",
            "- % Valid VMs            : 98.00%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Per VM check"
      ],
      "metadata": {
        "id": "AnWrD6rP_42W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure time_idx is integer and sorted\n",
        "val_df['time_idx'] = val_df['time_idx'].astype(int)\n",
        "val_df = val_df.sort_values([\"vm_id\", \"time_idx\"]).reset_index(drop=True)\n",
        "\n",
        "# Filter VMs that have enough data for validation\n",
        "valid_val_vms = val_df.groupby(\"vm_id\").filter(lambda x: x['time_idx'].nunique() >= max_prediction_length)\n",
        "invalid_vms = val_df['vm_id'].nunique() - valid_val_vms['vm_id'].nunique()\n",
        "\n",
        "print(f\"âœ… Valid VMs in val_df: {valid_val_vms['vm_id'].nunique()}\")\n",
        "print(f\"âš ï¸  Skipped VMs in val_df due to insufficient time_idx: {invalid_vms}\")\n",
        "\n",
        "val_df = valid_val_vms.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6foPowVl__P8",
        "outputId": "a34a27c7-0f3a-4a12-c3c5-8672fc4b6f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Valid VMs in val_df: 196\n",
            "âš ï¸  Skipped VMs in val_df due to insufficient time_idx: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and dataloaders ready"
      ],
      "metadata": {
        "id": "zs0rxyuQuH1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in relevant columns\n",
        "# fill_cols = ['disk_rolling_mean', 'network_rolling_mean', 'disk_rolling_std', 'network_rolling_std']\n",
        "# for col in fill_cols:\n",
        "#     if col in train_df.columns:\n",
        "#         train_df[col] = train_df[col].fillna(0)\n",
        "#     if col in val_df.columns:\n",
        "#         val_df[col] = val_df[col].fillna(0)\n",
        "\n",
        "# Prepare TimeSeriesDataSet for training portion (70%)\n",
        "\n",
        "dataset = TimeSeriesDataSet(\n",
        "    train_df,\n",
        "    time_idx='time_idx',\n",
        "    target=train_config[\"targets\"][0],  # 'cpu_utilization_ratio' here\n",
        "    group_ids=train_config[\"group_ids\"],\n",
        "    max_encoder_length=train_config[\"max_encoder_length\"],\n",
        "    max_prediction_length=train_config[\"max_prediction_length\"],\n",
        "    time_varying_known_reals=train_config[\"time_varying_known_reals\"],\n",
        "    time_varying_unknown_reals=train_config[\"time_varying_unknown_reals\"],\n",
        "    target_normalizer=GroupNormalizer(groups=train_config[\"group_ids\"]),\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    add_encoder_length=True,\n",
        "    allow_missing_timesteps=True\n",
        ")\n",
        "\n",
        "# Validation dataset for prediction (no randomization, full data)\n",
        "# âœ… \"TimeSeriesDataSet applies sliding window logic on the training data,\n",
        "# using the full configuration like past steps, future steps, groups, and prepares the dataset accordingly.\"\n",
        "\n",
        "# Filter val_df to include only VMs with sufficient data for prediction\n",
        "required_val_steps = train_config[\"max_prediction_length\"]\n",
        "valid_val_vms_filtered = val_df.groupby(\"vm_id\").filter(lambda x: x['time_idx'].nunique() >= required_val_steps)\n",
        "\n",
        "# Reset index before creating the validation dataset\n",
        "val_df_for_dataset = valid_val_vms_filtered.reset_index(drop=True)\n",
        "\n",
        "val_dataset = TimeSeriesDataSet.from_dataset(\n",
        "    dataset,\n",
        "    val_df_for_dataset,\n",
        "    predict=True,\n",
        "    stop_randomization=True\n",
        ")\n",
        "\n",
        "\n",
        "# Create dataloaders\n",
        "# performs Batching, Padding, Time-aware slicing for forecasting\n",
        "\n",
        "train_dataloader = dataset.to_dataloader(\n",
        "    train=True,\n",
        "    batch_size=train_config[\"batch_size\"],\n",
        "    num_workers=train_config[\"num_workers\"]\n",
        ")\n",
        "\n",
        "val_dataloader = val_dataset.to_dataloader(\n",
        "    train=False,\n",
        "    batch_size=train_config[\"batch_size\"],\n",
        "    num_workers=train_config[\"num_workers\"]\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"âœ… Dataset and dataloaders ready. Train batches: {len(train_dataloader)}, Val batches: {len(val_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "RkrZt4FfzkVZ",
        "outputId": "764cc95d-5755-4a11-eb3a-c49896156362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "filters should not remove entries all entries - check encoder/decoder lengths and lags",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-61-109522933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mval_df_for_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_val_vms_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m val_dataset = TimeSeriesDataSet.from_dataset(\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mval_df_for_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries/_timeseries.py\u001b[0m in \u001b[0;36mfrom_dataset\u001b[0;34m(cls, dataset, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1661\u001b[0m             \u001b[0mnew\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \"\"\"\n\u001b[0;32m-> 1663\u001b[0;31m         return cls.from_parameters(\n\u001b[0m\u001b[1;32m   1664\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries/_timeseries.py\u001b[0m in \u001b[0;36mfrom_parameters\u001b[0;34m(cls, parameters, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries/_timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# create index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# data conversion to torch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries/_timeseries.py\u001b[0m in \u001b[0;36m_construct_index\u001b[0;34m(self, data, predict_mode)\u001b[0m\n\u001b[1;32m   1859\u001b[0m             \u001b[0;34m\"check encoder/decoder lengths and lags\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         )\n\u001b[0;32m-> 1861\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: filters should not remove entries all entries - check encoder/decoder lengths and lags"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output & Log Folder Creation"
      ],
      "metadata": {
        "id": "BoJ1pukZhskL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup output and log folders based on run config\n",
        "\n",
        "import pytz\n",
        "import datetime\n",
        "\n",
        "ist = pytz.timezone('Asia/Kolkata')\n",
        "now_ist = datetime.datetime.now(ist)\n",
        "timestamp = now_ist.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "def get_run_folder_name(train_config, vm_count):\n",
        "    target = \"cpu\"\n",
        "    past = f\"past{train_config['max_encoder_length']}\"\n",
        "    fut = f\"fut{train_config['max_prediction_length']}\"\n",
        "    batch = f\"bs{train_config['batch_size']}\"\n",
        "    lr = f\"lr{train_config['learning_rate']:.0e}\".replace('+0', '')\n",
        "    hid = f\"hid{train_config['hidden_size']}\"\n",
        "\n",
        "    return f\"{target}_{vm_count}_{past}_{fut}_{batch}_{lr}_{hid}_{timestamp}\"\n",
        "\n",
        "folder_name = get_run_folder_name(train_config, vm_count)\n",
        "\n",
        "train_config[\"output_base_dir\"] = os.path.join(train_config[\"output_base_dir\"], folder_name)\n",
        "train_config[\"log_dir\"] = os.path.join(train_config[\"log_dir\"], folder_name)\n",
        "\n",
        "os.makedirs(train_config[\"output_base_dir\"], exist_ok=True)\n",
        "os.makedirs(train_config[\"log_dir\"], exist_ok=True)\n",
        "\n",
        "print(\"Output directory:\", train_config[\"output_base_dir\"])\n",
        "print(\"Log directory:\", train_config[\"log_dir\"])\n",
        "\n",
        "# Now you can proceed to model training using `tft_df` and `train_config` as usual."
      ],
      "metadata": {
        "id": "Ib5yqZQz-9PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging & Callbacks"
      ],
      "metadata": {
        "id": "tLG5FXgbvkJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging & Callbacks\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "for target in train_config[\"targets\"]:\n",
        "    print(f\"\\nðŸ” Training for target: {target}\")\n",
        "\n",
        "    run_dir = os.path.join(train_config[\"output_base_dir\"], f\"{target}_run_{timestamp}\")\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    # Save Raw cleaned DF for inspection (TFT input format)\n",
        "    tft_df.to_csv(f\"{run_dir}/tft_df.csv\", index=False)\n",
        "\n",
        "    # Save structured TimeSeriesDataset (structure, scalers, etc.)\n",
        "    dataset.save(f\"{run_dir}/tft_df_metadata\")  # <-- .save stores dataset metadata\n",
        "\n",
        "    # Save metadata for mapping forecasts (VM, time)\n",
        "    meta_cols = ['vm_id', 'timestamp', 'time_idx']\n",
        "\n",
        "    if all(col in val_df.columns for col in meta_cols):\n",
        "        meta_df = val_df[meta_cols].reset_index(drop=True)\n",
        "        meta_df.to_csv(f\"{run_dir}/forecast_metadata.csv\", index=False)\n",
        "        print(f\"âœ… Metadata saved to: {run_dir}/forecast_metadata.csv\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Skipping metadata save â€” columns not found: {meta_cols}\")\n",
        "\n",
        "    # Setup logging & checkpointing\n",
        "    logger = CSVLogger(save_dir=train_config[\"log_dir\"], name=f\"{target}_log\")\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        monitor=\"val_loss\",\n",
        "        dirpath=run_dir,\n",
        "        filename=\"tft-{epoch:02d}-{val_loss:.2f}\",\n",
        "        save_top_k=1,\n",
        "        save_last=True,\n",
        "        mode=\"min\"\n",
        "    )\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=train_config[\"early_stopping_patience\"],\n",
        "        mode=\"min\"\n",
        "    )"
      ],
      "metadata": {
        "id": "X07NZKn0SeUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model, Lightning, Trainer"
      ],
      "metadata": {
        "id": "XuuT4XcivziV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "\n",
        "class TFTLightningModule(pl.LightningModule):\n",
        "    def __init__(self, tft_model: TemporalFusionTransformer, learning_rate: float, loss_fn: torch.nn.Module):\n",
        "        super().__init__()\n",
        "        self.tft_model = tft_model\n",
        "        self.learning_rate = learning_rate\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.tft_model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat.prediction, y) # Extract prediction from output\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat.prediction, y) # Extract prediction from output\n",
        "        self.log(\"val_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "# Create the TFT model\n",
        "tft_model = TemporalFusionTransformer.from_dataset(\n",
        "    dataset,\n",
        "    learning_rate=train_config[\"learning_rate\"],\n",
        "    hidden_size=train_config[\"hidden_size\"],\n",
        "    dropout=train_config[\"dropout\"],\n",
        "    loss=train_config[\"loss_fn\"],\n",
        "    log_interval=10,\n",
        "    reduce_on_plateau_patience=4\n",
        ")\n",
        "\n",
        "# Wrap the TFT model in a LightningModule\n",
        "model = TFTLightningModule(\n",
        "    tft_model=tft_model,\n",
        "    learning_rate=train_config[\"learning_rate\"],\n",
        "    loss_fn=train_config[\"loss_fn\"]\n",
        ")\n",
        "\n",
        "# Setup Trainer\n",
        "if torch.cuda.is_available():\n",
        "    accelerator = \"gpu\"\n",
        "    devices = 1\n",
        "else:\n",
        "    accelerator = \"cpu\"\n",
        "    devices = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=train_config[\"epochs\"],\n",
        "    accelerator=accelerator,\n",
        "    devices=devices,\n",
        "    logger=logger,\n",
        "    callbacks=[checkpoint_callback, early_stopping],\n",
        "    enable_checkpointing=True\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
      ],
      "metadata": {
        "id": "paex9VsEaJBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actual vs Prediction Graphs"
      ],
      "metadata": {
        "id": "YAkb7l6BytSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”® Step 1: Make raw predictions on validation set\n",
        "prediction_output = model.tft_model.predict(\n",
        "    val_dataloader, mode='raw', return_x=True\n",
        ")\n",
        "\n",
        "# âœ… Step 2: Extract input and output\n",
        "x = prediction_output.x\n",
        "predictions = prediction_output.output\n",
        "\n",
        "# âœ… Step 3: Extract forecast values as numpy array (for CSV export)\n",
        "forecast = predictions.prediction[0].detach().cpu().numpy()\n",
        "\n",
        "# âœ… Step 4: Plot forecast using built-in TFT visualization\n",
        "fig = model.tft_model.plot_prediction(\n",
        "    x, predictions, idx=0, show_future_observed=True\n",
        ")\n",
        "plt.title(f\"Prediction Plot for {target}\")\n",
        "\n",
        "# âœ… Reduce legend size and move it neatly outside\n",
        "plt.legend(\n",
        "    loc='upper left',\n",
        "    bbox_to_anchor=(1, 1),\n",
        "    fontsize='small',      # You can try 'small', 'x-small', numeric values like 8\n",
        "    frameon=True,          # Adds box around legend for clarity\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# âœ… Step 5: Save the plot as PNG\n",
        "plt.savefig(f\"{run_dir}/plot.png\", bbox_inches='tight')  # Ensure nothing gets cut off\n",
        "plt.close()\n",
        "print(f\"âœ… Prediction plot saved at: {run_dir}/plot.png\")\n",
        "\n",
        "# âœ… Step 6: Save forecast to CSV\n",
        "pd.DataFrame(forecast, columns=[f'{target}_forecast']).to_csv(\n",
        "    f\"{run_dir}/predictions.csv\", index=False\n",
        ")\n",
        "print(f\"âœ… Forecast values saved to: {run_dir}/predictions.csv\")"
      ],
      "metadata": {
        "id": "B2qLHzHdywHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spike Detection & Save Metadata"
      ],
      "metadata": {
        "id": "Wp2UKawDwVRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spikes = forecast > np.percentile(forecast, 95)\n",
        "\n",
        "# Save run notes and spike count\n",
        "with open(f\"{run_dir}/notes.txt\", \"w\") as f:\n",
        "    f.write(f\"Target: {target}\\n\")\n",
        "    f.write(f\"Spikes > 95th percentile: {int(spikes.sum())}\\n\")\n",
        "    f.write(\"Review plot.png and predictions.csv for further insights.\\n\")\n",
        "\n",
        "# ðŸ’¾ Save training config for reproducibility\n",
        "# Create a serializable version of train_config\n",
        "serializable_train_config = train_config.copy()\n",
        "# Replace the non-serializable loss_fn object with its name\n",
        "serializable_train_config[\"loss_fn\"] = serializable_train_config[\"loss_fn\"].__class__.__name__\n",
        "\n",
        "with open(f\"{run_dir}/modelconfig.json\", \"w\") as f:\n",
        "    json.dump(serializable_train_config, f, indent=2)\n",
        "\n",
        "print(f\"âœ… Run complete. Outputs saved at: {run_dir}\")"
      ],
      "metadata": {
        "id": "ZZViKR3poBY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_path = os.path.join(run_dir, \"predictions.csv\")\n",
        "print(f\"âœ… Forecast values saved to: {forecast_path}\")"
      ],
      "metadata": {
        "id": "5iELq2nboDno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Command to inspect .ckpt\n",
        "\n",
        "# ckpt = torch.load(\"path/to/tft-epoch=01-val_loss=0.04.ckpt\", map_location=torch.device('cpu'))\n",
        "# print(ckpt.keys())"
      ],
      "metadata": {
        "id": "rxsLstiSU8nn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(ckpt[\"epoch\"])             # Epoch number\n",
        "# print(ckpt[\"global_step\"])       # Total steps\n",
        "# print(ckpt[\"hyper_parameters\"])  # Saved hyperparameters"
      ],
      "metadata": {
        "id": "ebOmwcNBVDlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k9bYj41m4Dc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6f56c8b",
        "outputId": "2d6c0a9f-cad1-402a-9aef-a2aed3e5aea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Diagnose the AssertionError in val_dataset creation\n",
        "\n",
        "required_prediction_length = train_config[\"max_prediction_length\"]\n",
        "print(f\"Checking validation data for VMs with less than {required_prediction_length} consecutive time steps.\")\n",
        "\n",
        "invalid_vms_for_prediction = []\n",
        "\n",
        "for vm_id, group_df in val_df_for_dataset.groupby('vm_id', observed=False):\n",
        "    # Check for continuous time indices\n",
        "    time_indices = group_df['time_idx'].sort_values().tolist()\n",
        "    if not time_indices:\n",
        "        invalid_vms_for_prediction.append(vm_id)\n",
        "        print(f\"  - VM {vm_id}: No time indices found.\")\n",
        "        continue\n",
        "\n",
        "    # Check if there is any sequence of length required_prediction_length\n",
        "    # A simple check is to see if the total number of time steps is enough\n",
        "    # for at least one sequence. More robust check would involve looking for gaps.\n",
        "    max_possible_sequences = max(0, time_indices[-1] - time_indices[0] - required_prediction_length + 2)\n",
        "\n",
        "\n",
        "    if group_df['time_idx'].nunique() < required_prediction_length:\n",
        "         invalid_vms_for_prediction.append(vm_id)\n",
        "         print(f\"  - VM {vm_id}: Total unique time steps ({group_df['time_idx'].nunique()}) is less than required prediction length ({required_prediction_length}).\")\n",
        "\n",
        "    # More thorough check for gaps - simplified approach\n",
        "    # Check if the difference between consecutive time_idx is always 1\n",
        "    if not all(diff == 1 for diff in np.diff(time_indices)):\n",
        "         # This VM has gaps. Let's check if there's *at least one* valid sequence possible\n",
        "         # A valid sequence needs required_prediction_length consecutive time_idx values.\n",
        "         # This is a simplified check and might not catch all edge cases with multiple small gaps.\n",
        "         has_valid_sequence = False\n",
        "         if len(time_indices) >= required_prediction_length:\n",
        "             for i in range(len(time_indices) - required_prediction_length + 1):\n",
        "                 if all(time_indices[i+j] == time_indices[i] + j for j in range(required_prediction_length)):\n",
        "                     has_valid_sequence = True\n",
        "                     break\n",
        "         if not has_valid_sequence:\n",
        "              invalid_vms_for_prediction.append(vm_id)\n",
        "              print(f\"  - VM {vm_id}: Has gaps or not enough consecutive time steps for prediction sequences.\")\n",
        "\n",
        "\n",
        "# Remove duplicate VM IDs if any were added multiple times\n",
        "invalid_vms_for_prediction = list(set(invalid_vms_for_prediction))\n",
        "\n",
        "if invalid_vms_for_prediction:\n",
        "    print(f\"\\nâš ï¸ Found {len(invalid_vms_for_prediction)} VMs causing issues for validation dataset creation:\")\n",
        "    print(invalid_vms_for_prediction)\n",
        "    print(\"\\nThese VMs likely do not have a continuous sequence of time indices of length equal to or greater than the max_prediction_length in the validation set.\")\n",
        "else:\n",
        "    print(\"\\nâœ… All VMs in val_df_for_dataset appear to have enough consecutive time steps for prediction sequences.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking validation data for VMs with less than 2016 consecutive time steps.\n",
            "  - VM 94: No time indices found.\n",
            "  - VM 97: No time indices found.\n",
            "  - VM 103: No time indices found.\n",
            "  - VM 104: No time indices found.\n",
            "  - VM 111: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 116: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 117: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 907: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 910: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 911: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 912: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 914: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 915: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 917: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 920: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 930: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 931: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 933: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 941: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 942: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 947: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 949: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 950: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 951: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 952: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 953: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 954: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 956: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1017: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1024: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1025: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1026: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1039: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1049: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1053: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1055: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1058: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1059: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1060: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1063: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1066: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1067: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1070: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1071: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1075: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1080: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1081: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1082: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1090: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1095: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1096: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1100: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1112: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1115: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1117: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1118: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1119: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1125: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1140: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1142: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1146: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1158: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1160: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1165: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1166: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1173: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1177: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "  - VM 1185: Has gaps or not enough consecutive time steps for prediction sequences.\n",
            "\n",
            "âš ï¸ Found 68 VMs causing issues for validation dataset creation:\n",
            "[1024, 1025, 1026, 1158, 1160, 907, 1165, 910, 911, 912, 1039, 914, 915, 1166, 917, 1173, 920, 1049, 1177, 1053, 1055, 1185, 930, 931, 1058, 933, 1059, 1060, 1063, 1066, 1067, 941, 942, 1070, 1071, 947, 1075, 949, 950, 951, 952, 953, 954, 1080, 956, 1081, 1082, 1090, 1095, 1096, 1100, 1112, 1115, 1117, 94, 1118, 1119, 97, 1125, 103, 104, 111, 116, 117, 1140, 1142, 1017, 1146]\n",
            "\n",
            "These VMs likely do not have a continuous sequence of time indices of length equal to or greater than the max_prediction_length in the validation set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmkEnl8nF--f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2133a3972b28273c10fa027bbde5fb58efc69f3a1cd517826cf4b1affadfce4e"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}